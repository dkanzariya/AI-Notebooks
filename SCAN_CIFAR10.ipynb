{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCAN_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RaWimx9TStu2C4v-jKPUzYVzwGojsAzB",
      "authorship_tag": "ABX9TyP7xXcHo/wWU4uhzyX5w6wr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkanzariya/Computer-Vision/blob/main/SCAN_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4m8FjQP6ixD",
        "outputId": "2211845c-7364-44fc-fbef-1dab77017dcc"
      },
      "source": [
        "!git clone https://github.com/wvangansbeke/Unsupervised-Classification.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Unsupervised-Classification'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Total 166 (delta 0), reused 0 (delta 0), pack-reused 166\u001b[K\n",
            "Receiving objects: 100% (166/166), 13.41 MiB | 44.28 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMM_rCVR6vUP",
        "outputId": "47fba309-6e25-4eef-8f3f-9807b1d77d77"
      },
      "source": [
        "%cd Unsupervised-Classification/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Unsupervised-Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGs6oIwBBrO3",
        "outputId": "302a9a28-49f0-42b0-db05-8d914457e1b8"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "pretrain_path = \"/content/drive/MyDrive/SCAN/simclr_cifar-10.pth.tar\"\n",
        "\n",
        "state_dict = torch.load(pretrain_path,map_location=torch.device('cuda'))\n",
        "\n",
        "from models.models import ContrastiveModel\n",
        "from models.resnet_cifar import resnet18\n",
        "backbone = resnet18()\n",
        "model = ContrastiveModel(backbone,head='mlp',features_dim=128)\n",
        "        # model = ContrastiveModel(backbone, **p['model_kwargs'])\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ContrastiveModel(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (contrastive_head): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epjVp_9BDB34",
        "outputId": "6d76ce50-b6bb-455d-bfdf-b0dc2ea22ca6"
      },
      "source": [
        "train_dataset.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfaj05B8DCGq",
        "outputId": "8b41ec2d-a97e-4df9-dae8-63b915d0bd34"
      },
      "source": [
        "len(train_dataloader), 97 * 512"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 49664)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJJuXCLxDCVD",
        "outputId": "6555c197-e617-4253-cbfb-065e8677e887"
      },
      "source": [
        "# from the train set lets get a embedding for each image  \n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 512\n",
        "\n",
        "true_labels = []\n",
        "images = np.zeros(((len(train_dataloader)-1) * batch_size,128))\n",
        "model = model.cuda()\n",
        " \n",
        "#get 500 images from train  \n",
        "for i,data in tqdm(enumerate(train_dataloader)): \n",
        "    try: \n",
        "        if  i < len(train_dataloader)-1:  \n",
        "            true_labels.extend(data['target'])\n",
        "        images[i * batch_size : (i+1) * batch_size] = model(data['image'].cuda()).cpu().detach().numpy()\n",
        "    except ValueError: \n",
        "        np.append(images,model(data['image'].cuda()).cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "98it [00:10,  9.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL4w1C_sDCg8",
        "outputId": "7b2c2342-df38-4cb3-bfa4-b21c9835951c"
      },
      "source": [
        "images.shape,len(true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49664, 128), 49664)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mhoyoxkDR0R",
        "outputId": "3be45cb5-dea0-4fb0-cbfa-648d0c03ed0a"
      },
      "source": [
        "#train kmeans \n",
        "from sklearn.cluster import KMeans \n",
        "\n",
        "kModel = KMeans(n_clusters = 10,n_jobs=-1,random_state = 101,max_iter = 1000,init = 'random',n_init=100)\n",
        " \n",
        "# Training the model\n",
        "kModel.fit(images)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='random', max_iter=1000,\n",
              "       n_clusters=10, n_init=100, n_jobs=-1, precompute_distances='auto',\n",
              "       random_state=101, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_niMRiqDSit",
        "outputId": "74168b48-55a1-4b10-980e-f1b79e7afe41"
      },
      "source": [
        "classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "print(f\"classes : {classes}\")\n",
        "\n",
        "n_samples = 1000\n",
        "\n",
        "kmeans_labels_dict = {}\n",
        "\n",
        "for data in train_dataset:\n",
        "       \n",
        "    if classes == []:\n",
        "      print(\"embedding for all classes found now stopping\")\n",
        "      break\n",
        "\n",
        "    className = data['meta']['class_name']\n",
        "   \n",
        "\n",
        "    if className in classes: \n",
        "       \n",
        "       embedding = model(data['image'].unsqueeze(0).cuda()).cpu().detach().numpy()\n",
        "       \n",
        "       kmeans_label = kModel.predict(embedding)\n",
        "       \n",
        "      #  print(f\"Class Target : {data['target']}  Kmeans Target {kmeans_label} Class Name {className}\")\n",
        "\n",
        "\n",
        "       if kmeans_labels_dict.get(className,None) is None: \n",
        "          kmeans_labels_dict[className] = [kmeans_label[0]]\n",
        "        \n",
        "       else:\n",
        "          kmeans_labels_dict[className].append(kmeans_label[0])\n",
        "          \n",
        "       # Here you can increase  \n",
        "       if len(kmeans_labels_dict[className]) == n_samples:\n",
        "\n",
        "          print(f'For  :: {className}  {kmeans_labels_dict[className]}') \n",
        "  \n",
        "          classes.remove(className)\n",
        "\n",
        "# kmeans_labels_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classes : ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "For  :: bird  [7, 1, 2, 3, 1, 6, 7, 7, 2, 1, 9, 3, 9, 2, 7, 7, 9, 7, 8, 7, 2, 9, 1, 5, 7, 7, 8, 4, 5, 8, 3, 1, 2, 4, 8, 7, 7, 9, 4, 5, 7, 1, 3, 4, 9, 7, 7, 9, 8, 2, 9, 7, 8, 5, 2, 2, 1, 0, 9, 3, 7, 4, 9, 3, 2, 8, 7, 7, 9, 4, 7, 9, 7, 2, 0, 7, 7, 7, 2, 7, 8, 2, 7, 9, 0, 7, 9, 8, 8, 9, 2, 9, 3, 2, 2, 1, 1, 3, 2, 3, 7, 2, 7, 1, 7, 2, 9, 8, 9, 9, 1, 2, 0, 2, 5, 9, 7, 1, 2, 1, 3, 3, 2, 1, 9, 7, 7, 7, 4, 9, 1, 8, 5, 2, 9, 9, 3, 9, 7, 7, 9, 8, 9, 9, 1, 4, 9, 7, 7, 9, 4, 8, 2, 1, 2, 3, 4, 0, 7, 9, 7, 2, 3, 4, 3, 1, 2, 4, 2, 5, 4, 3, 2, 2, 9, 2, 2, 7, 9, 8, 4, 3, 2, 4, 8, 2, 9, 3, 7, 7, 7, 2, 8, 1, 2, 7, 4, 9, 4, 2, 2, 6, 7, 9, 0, 3, 2, 9, 2, 9, 2, 1, 4, 2, 7, 9, 4, 2, 2, 3, 7, 7, 2, 2, 7, 7, 8, 9, 1, 1, 7, 1, 3, 2, 4, 7, 1, 9, 3, 9, 8, 8, 8, 7, 8, 0, 7, 3, 2, 9, 9, 9, 2, 1, 9, 1, 2, 6, 2, 3, 3, 2, 2, 8, 7, 3, 1, 7, 3, 1, 9, 2, 2, 3, 9, 9, 8, 6, 2, 9, 9, 7, 8, 2, 7, 7, 2, 3, 9, 7, 1, 1, 6, 7, 1, 3, 9, 3, 2, 7, 3, 7, 8, 8, 8, 2, 3, 8, 9, 2, 1, 4, 3, 3, 1, 1, 2, 6, 9, 2, 4, 7, 2, 9, 7, 9, 7, 7, 7, 7, 9, 1, 2, 2, 9, 2, 9, 8, 7, 3, 9, 0, 3, 2, 2, 9, 3, 2, 7, 9, 2, 9, 4, 7, 1, 3, 9, 9, 9, 7, 9, 7, 9, 4, 7, 2, 8, 8, 2, 2, 4, 6, 1, 9, 7, 7, 2, 1, 4, 9, 8, 4, 7, 9, 2, 7, 7, 8, 7, 1, 4, 1, 7, 2, 9, 3, 8, 1, 9, 2, 9, 0, 3, 9, 2, 5, 2, 9, 1, 7, 7, 5, 9, 2, 8, 8, 3, 1, 1, 6, 4, 8, 4, 9, 9, 9, 9, 9, 7, 0, 9, 7, 9, 9, 8, 7, 9, 7, 2, 9, 3, 7, 7, 8, 7, 7, 0, 9, 2, 2, 7, 5, 2, 7, 3, 5, 8, 4, 9, 9, 8, 9, 9, 8, 8, 4, 9, 1, 5, 2, 8, 2, 3, 3, 9, 9, 3, 5, 8, 9, 9, 2, 9, 2, 5, 2, 4, 9, 5, 9, 1, 4, 7, 1, 7, 9, 9, 7, 2, 8, 8, 9, 9, 3, 9, 7, 9, 3, 7, 0, 1, 2, 8, 9, 1, 4, 7, 1, 9, 7, 7, 6, 9, 9, 3, 4, 2, 9, 4, 6, 5, 2, 1, 4, 3, 7, 1, 7, 1, 1, 7, 2, 7, 4, 4, 2, 3, 9, 7, 0, 3, 9, 8, 2, 5, 2, 4, 8, 2, 9, 7, 9, 2, 2, 2, 2, 7, 6, 4, 8, 7, 2, 8, 9, 0, 0, 8, 7, 8, 9, 0, 7, 7, 5, 1, 7, 9, 1, 7, 9, 7, 9, 7, 1, 9, 2, 2, 2, 8, 9, 9, 7, 2, 8, 7, 8, 8, 2, 1, 8, 2, 9, 3, 6, 9, 2, 5, 8, 9, 9, 2, 5, 4, 2, 1, 2, 2, 9, 1, 3, 4, 4, 7, 2, 3, 2, 2, 9, 6, 9, 9, 2, 3, 9, 2, 9, 3, 8, 2, 9, 9, 4, 5, 1, 3, 1, 2, 2, 9, 9, 7, 2, 9, 2, 8, 5, 1, 0, 2, 5, 3, 3, 5, 1, 9, 4, 7, 3, 3, 1, 9, 3, 9, 7, 2, 7, 8, 7, 1, 7, 9, 7, 1, 4, 2, 9, 7, 5, 2, 1, 8, 2, 1, 3, 3, 7, 3, 7, 3, 9, 9, 1, 7, 7, 9, 2, 9, 2, 3, 7, 7, 9, 7, 8, 6, 8, 1, 7, 7, 4, 4, 9, 3, 8, 7, 7, 7, 7, 0, 2, 7, 7, 8, 1, 2, 5, 2, 8, 7, 0, 1, 3, 9, 7, 9, 9, 9, 3, 3, 7, 2, 2, 2, 7, 2, 8, 8, 2, 2, 7, 0, 2, 8, 3, 2, 7, 9, 1, 1, 9, 9, 2, 2, 8, 9, 7, 7, 7, 9, 7, 7, 3, 9, 2, 8, 9, 4, 5, 9, 6, 9, 7, 7, 2, 3, 0, 1, 9, 8, 1, 7, 2, 7, 9, 2, 8, 8, 8, 1, 3, 2, 3, 1, 7, 9, 5, 8, 7, 9, 4, 7, 2, 7, 5, 4, 1, 1, 2, 2, 7, 9, 7, 4, 3, 3, 4, 3, 8, 2, 9, 5, 8, 2, 9, 2, 8, 1, 1, 1, 2, 8, 1, 9, 8, 2, 1, 7, 9, 7, 7, 9, 3, 4, 2, 9, 5, 8, 9, 1, 7, 9, 7, 1, 3, 9, 4, 7, 2, 1, 2, 9, 5, 7, 2, 9, 1, 7, 9, 8, 1, 8, 3, 6, 7, 3, 4, 2, 8, 7, 7, 2, 8, 2, 7, 3, 2, 8, 7, 9, 9, 7, 8, 2, 9, 9, 2, 2, 7, 2, 1, 4, 7, 2, 9, 9, 1, 7, 8, 2, 1, 4, 7, 2, 9, 9, 2, 9, 3, 9, 8, 3, 7, 2, 2, 9, 2, 2, 8, 1, 9, 9, 9, 9, 1, 8, 9, 4, 7, 9, 3, 7, 9, 0, 4, 9, 7, 9, 1, 9, 8, 7, 2, 7, 9, 0, 2, 1, 8, 7, 2, 7, 9, 1, 9, 2, 2, 9, 7, 9, 2]\n",
            "For  :: ship  [2, 5, 2, 7, 6, 6, 4, 5, 7, 6, 5, 2, 7, 8, 8, 6, 8, 6, 6, 7, 5, 7, 1, 6, 8, 4, 5, 5, 6, 5, 7, 5, 6, 8, 6, 8, 8, 7, 5, 6, 4, 5, 2, 7, 1, 4, 8, 7, 7, 2, 5, 2, 2, 5, 6, 8, 5, 4, 0, 6, 7, 2, 1, 6, 5, 5, 4, 7, 5, 6, 8, 4, 7, 2, 8, 8, 2, 6, 2, 8, 6, 2, 7, 8, 7, 8, 1, 2, 5, 5, 5, 8, 5, 2, 5, 0, 8, 2, 2, 7, 5, 5, 2, 6, 2, 2, 5, 6, 5, 6, 5, 4, 2, 4, 5, 6, 7, 5, 6, 2, 2, 8, 4, 2, 7, 6, 6, 1, 5, 8, 4, 7, 2, 0, 6, 6, 6, 5, 6, 6, 4, 6, 6, 5, 5, 5, 8, 5, 2, 7, 4, 1, 5, 2, 6, 5, 6, 1, 5, 2, 8, 7, 8, 2, 7, 5, 7, 6, 4, 2, 5, 6, 7, 4, 5, 7, 6, 8, 2, 5, 2, 4, 6, 6, 8, 5, 6, 6, 1, 2, 7, 5, 4, 7, 4, 1, 8, 4, 8, 2, 1, 8, 2, 2, 4, 6, 6, 4, 8, 4, 4, 2, 8, 5, 7, 8, 5, 2, 8, 8, 7, 5, 5, 5, 5, 2, 1, 2, 5, 1, 6, 6, 2, 1, 2, 2, 6, 4, 5, 8, 8, 1, 4, 6, 8, 8, 6, 6, 2, 6, 6, 2, 2, 6, 2, 4, 6, 4, 2, 5, 8, 8, 4, 6, 7, 4, 5, 2, 7, 5, 8, 7, 1, 2, 4, 7, 8, 8, 8, 1, 6, 2, 6, 7, 2, 8, 7, 2, 6, 7, 2, 2, 9, 4, 4, 2, 5, 5, 8, 6, 5, 2, 2, 4, 2, 6, 2, 6, 6, 5, 6, 5, 5, 2, 8, 4, 4, 2, 2, 5, 7, 7, 4, 6, 5, 2, 6, 8, 8, 6, 1, 8, 4, 1, 8, 4, 2, 1, 5, 6, 5, 2, 2, 5, 2, 8, 0, 6, 8, 4, 7, 2, 2, 8, 7, 2, 6, 8, 6, 4, 8, 5, 5, 8, 7, 7, 5, 5, 6, 6, 4, 7, 8, 6, 5, 4, 1, 5, 6, 5, 2, 7, 4, 8, 2, 7, 1, 6, 5, 2, 6, 6, 7, 5, 5, 2, 2, 2, 7, 4, 5, 6, 2, 7, 1, 4, 4, 8, 4, 8, 6, 8, 2, 6, 2, 7, 8, 6, 5, 6, 4, 5, 1, 2, 2, 6, 4, 7, 6, 5, 1, 8, 2, 2, 7, 1, 2, 6, 8, 8, 8, 2, 2, 4, 4, 9, 0, 5, 4, 7, 5, 8, 4, 7, 2, 5, 8, 7, 7, 2, 8, 6, 5, 4, 1, 2, 7, 4, 5, 2, 8, 1, 7, 2, 5, 2, 6, 6, 8, 6, 2, 5, 6, 5, 5, 6, 8, 7, 7, 6, 6, 7, 7, 6, 6, 6, 2, 1, 8, 6, 6, 5, 8, 1, 4, 5, 6, 8, 2, 6, 5, 4, 6, 8, 6, 4, 2, 2, 5, 4, 8, 6, 4, 2, 8, 5, 5, 4, 1, 5, 2, 2, 6, 7, 6, 8, 5, 4, 6, 6, 7, 7, 8, 6, 2, 2, 7, 4, 5, 7, 6, 2, 7, 6, 2, 8, 8, 5, 6, 5, 5, 5, 1, 4, 8, 4, 8, 6, 8, 2, 2, 4, 8, 6, 8, 4, 4, 4, 7, 5, 2, 5, 8, 8, 7, 4, 4, 7, 5, 7, 4, 1, 6, 6, 1, 5, 7, 6, 8, 2, 6, 1, 6, 6, 5, 4, 8, 8, 6, 2, 5, 2, 4, 2, 5, 6, 2, 7, 7, 2, 7, 6, 8, 7, 2, 8, 7, 5, 6, 6, 4, 1, 8, 5, 7, 7, 8, 2, 2, 4, 2, 4, 8, 4, 8, 8, 5, 6, 2, 6, 5, 2, 5, 8, 8, 4, 2, 4, 6, 6, 5, 2, 1, 5, 6, 8, 8, 5, 1, 8, 8, 8, 7, 4, 8, 6, 6, 7, 4, 5, 7, 2, 6, 5, 2, 5, 5, 7, 7, 9, 2, 2, 5, 5, 2, 8, 1, 8, 2, 8, 4, 6, 5, 6, 6, 8, 2, 4, 6, 6, 5, 4, 6, 5, 2, 7, 9, 4, 2, 2, 5, 2, 4, 4, 8, 1, 5, 5, 7, 1, 2, 2, 8, 7, 2, 8, 4, 4, 8, 2, 6, 5, 2, 2, 8, 8, 2, 6, 5, 6, 7, 1, 2, 6, 7, 5, 2, 6, 7, 2, 1, 2, 4, 2, 8, 2, 1, 5, 6, 5, 7, 7, 8, 1, 6, 7, 2, 2, 2, 4, 2, 1, 6, 6, 4, 5, 4, 5, 2, 6, 2, 1, 6, 2, 2, 7, 5, 6, 4, 1, 8, 2, 7, 2, 4, 7, 8, 8, 1, 6, 2, 8, 4, 1, 2, 8, 8, 8, 6, 7, 6, 6, 2, 6, 5, 4, 5, 5, 2, 6, 2, 5, 4, 4, 4, 2, 5, 2, 4, 5, 2, 2, 5, 5, 5, 4, 1, 8, 2, 5, 6, 5, 2, 2, 6, 6, 4, 2, 2, 2, 5, 6, 2, 8, 2, 6, 8, 4, 2, 2, 8, 6, 8, 4, 1, 6, 1, 6, 2, 1, 2, 5, 2, 2, 4, 4, 7, 8, 7, 8, 4, 7, 8, 6, 2, 2, 2, 2, 1, 1, 6, 7, 1, 6, 4, 2, 6, 7, 1, 5, 2, 6, 2, 4, 4, 5, 6, 7, 5, 4, 4, 6, 6, 6, 2, 7, 4, 4, 6, 8, 4, 5, 6, 2, 5, 2, 5, 4, 5, 2, 6, 8, 6, 7, 8, 5, 1, 6, 4, 8, 4, 4, 5, 8, 7, 2, 2, 6, 5, 1, 6, 7, 6, 6, 5, 6, 6, 8, 4, 2, 6, 2, 1, 5, 2, 2, 8, 4, 5, 1, 4, 4, 2, 8, 4, 2, 8, 2, 2, 5, 8, 2, 5, 6, 4, 5, 4, 8, 2, 2]\n",
            "For  :: frog  [0, 0, 2, 3, 0, 4, 0, 1, 1, 3, 2, 2, 7, 3, 3, 4, 3, 0, 4, 3, 7, 2, 3, 4, 7, 9, 1, 7, 3, 3, 7, 4, 1, 3, 0, 4, 3, 8, 2, 7, 1, 4, 2, 0, 2, 3, 9, 3, 0, 3, 2, 9, 3, 2, 2, 3, 3, 0, 9, 2, 1, 2, 2, 9, 2, 0, 9, 7, 3, 2, 3, 9, 1, 7, 4, 8, 3, 9, 2, 3, 7, 0, 1, 4, 3, 3, 9, 3, 9, 3, 1, 5, 2, 3, 4, 2, 2, 1, 2, 9, 2, 2, 2, 3, 3, 2, 3, 3, 3, 2, 8, 7, 3, 3, 7, 3, 3, 9, 2, 1, 7, 3, 8, 3, 1, 3, 3, 7, 2, 8, 2, 3, 2, 2, 2, 2, 3, 2, 2, 7, 1, 2, 0, 3, 8, 7, 0, 3, 9, 3, 0, 3, 2, 1, 3, 3, 2, 3, 2, 3, 2, 2, 0, 3, 2, 3, 1, 2, 2, 3, 1, 4, 2, 2, 7, 7, 2, 1, 8, 0, 8, 2, 3, 1, 3, 3, 7, 1, 2, 4, 2, 7, 2, 3, 1, 3, 3, 3, 7, 2, 1, 3, 2, 3, 8, 4, 7, 8, 3, 3, 3, 3, 7, 7, 7, 2, 3, 4, 3, 3, 3, 0, 1, 3, 1, 1, 1, 2, 2, 2, 3, 2, 1, 3, 4, 3, 3, 3, 1, 3, 3, 3, 3, 7, 2, 3, 1, 2, 1, 2, 7, 2, 2, 1, 9, 9, 4, 3, 2, 9, 8, 2, 7, 3, 0, 2, 3, 4, 2, 2, 1, 8, 3, 1, 2, 3, 3, 2, 7, 1, 1, 7, 3, 7, 4, 0, 9, 7, 2, 3, 7, 1, 3, 2, 1, 3, 1, 7, 3, 2, 2, 1, 3, 3, 1, 0, 2, 2, 9, 0, 2, 1, 2, 7, 8, 2, 9, 1, 0, 3, 3, 2, 1, 3, 4, 2, 1, 2, 2, 3, 3, 1, 3, 7, 3, 2, 4, 3, 2, 2, 9, 1, 2, 2, 7, 9, 9, 2, 2, 2, 2, 2, 9, 8, 2, 3, 3, 2, 2, 2, 4, 7, 2, 2, 4, 1, 4, 3, 4, 2, 3, 5, 8, 1, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 0, 3, 2, 1, 1, 3, 3, 2, 3, 0, 2, 2, 2, 9, 7, 0, 7, 1, 3, 7, 2, 2, 9, 2, 3, 2, 3, 2, 9, 1, 7, 3, 1, 2, 1, 9, 1, 2, 8, 2, 9, 2, 3, 1, 2, 1, 3, 2, 7, 3, 0, 3, 3, 1, 2, 2, 2, 7, 2, 9, 9, 0, 7, 3, 2, 3, 2, 2, 2, 0, 4, 2, 4, 2, 4, 3, 3, 5, 3, 3, 4, 0, 1, 3, 7, 2, 2, 0, 3, 3, 3, 2, 3, 7, 9, 0, 2, 2, 4, 7, 2, 3, 2, 3, 7, 0, 7, 4, 3, 3, 3, 3, 0, 1, 3, 3, 5, 7, 2, 4, 0, 2, 2, 4, 4, 2, 3, 2, 3, 9, 3, 3, 4, 7, 1, 1, 2, 9, 9, 2, 3, 2, 4, 9, 4, 3, 2, 4, 0, 7, 4, 9, 9, 0, 3, 2, 1, 2, 7, 2, 3, 9, 3, 3, 2, 2, 2, 2, 3, 9, 9, 2, 2, 7, 2, 4, 4, 0, 1, 1, 2, 3, 6, 3, 2, 9, 9, 9, 7, 4, 4, 0, 3, 2, 2, 2, 2, 2, 0, 1, 3, 2, 1, 2, 7, 3, 6, 2, 4, 7, 2, 4, 3, 7, 3, 4, 1, 3, 3, 3, 3, 7, 3, 2, 7, 1, 4, 3, 3, 7, 4, 1, 3, 1, 2, 3, 4, 2, 9, 3, 1, 9, 2, 9, 3, 0, 2, 2, 3, 2, 2, 2, 1, 3, 1, 4, 8, 3, 2, 2, 8, 0, 2, 1, 8, 3, 7, 2, 3, 2, 3, 2, 2, 2, 3, 2, 3, 8, 3, 9, 3, 2, 6, 2, 1, 2, 4, 9, 2, 7, 3, 4, 3, 9, 2, 9, 0, 3, 2, 9, 1, 8, 8, 3, 3, 3, 1, 3, 2, 3, 3, 3, 3, 9, 3, 2, 7, 2, 9, 2, 3, 3, 2, 2, 1, 2, 7, 8, 9, 2, 3, 3, 3, 2, 2, 7, 0, 4, 4, 4, 4, 9, 4, 7, 2, 2, 3, 3, 9, 2, 1, 2, 7, 9, 1, 3, 3, 8, 1, 7, 2, 9, 7, 2, 1, 3, 3, 2, 0, 1, 2, 3, 1, 2, 2, 0, 3, 3, 4, 8, 3, 2, 1, 3, 2, 1, 3, 3, 7, 3, 0, 7, 2, 3, 2, 3, 3, 8, 2, 4, 4, 9, 3, 3, 3, 3, 2, 3, 3, 1, 3, 3, 2, 3, 2, 2, 8, 4, 3, 9, 0, 3, 9, 9, 2, 2, 4, 2, 8, 3, 2, 1, 7, 3, 7, 4, 2, 2, 4, 9, 0, 8, 9, 2, 2, 1, 3, 1, 9, 2, 3, 2, 4, 3, 7, 3, 1, 0, 2, 9, 2, 7, 4, 1, 9, 2, 9, 1, 2, 2, 8, 9, 2, 8, 2, 7, 2, 9, 1, 2, 2, 2, 9, 1, 4, 2, 8, 7, 3, 1, 2, 8, 1, 9, 2, 3, 3, 9, 0, 7, 2, 2, 2, 3, 3, 1, 2, 1, 2, 7, 1, 2, 9, 3, 6, 1, 7, 0, 7, 3, 7, 8, 2, 3, 2, 8, 3, 3, 2, 9, 2, 7, 2, 2, 8, 1, 3, 2, 1, 7, 2, 9, 3, 3, 3, 7, 9, 2, 7, 4, 7, 7, 3, 3, 9, 2, 1, 4, 9, 3, 9, 3, 1, 2, 7, 3, 7, 1, 7, 3, 2, 3, 2, 0, 7, 2, 3, 2, 0, 2, 9, 2, 7, 8, 8, 9, 3, 4, 3, 2, 1, 9, 3, 7, 9, 3, 2, 7, 7, 7, 7, 9, 3, 7, 4, 2, 7, 3, 1, 0, 2, 3, 3, 2, 1, 1]\n",
            "For  :: cat  [1, 0, 0, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 8, 2, 0, 0, 8, 2, 9, 3, 8, 1, 8, 0, 0, 9, 0, 9, 0, 0, 3, 8, 0, 1, 1, 9, 2, 1, 4, 8, 9, 1, 2, 1, 0, 0, 0, 8, 9, 9, 8, 2, 4, 9, 8, 3, 9, 0, 9, 9, 3, 8, 9, 0, 3, 1, 8, 8, 8, 0, 0, 0, 2, 0, 9, 4, 9, 1, 9, 0, 0, 0, 1, 2, 1, 8, 4, 0, 0, 0, 9, 3, 3, 4, 4, 3, 9, 0, 1, 3, 8, 8, 0, 7, 3, 0, 0, 0, 9, 3, 8, 9, 9, 8, 0, 2, 0, 0, 2, 0, 4, 0, 1, 2, 8, 0, 2, 4, 0, 9, 1, 2, 9, 8, 1, 1, 9, 9, 0, 1, 1, 1, 9, 2, 9, 2, 7, 7, 0, 0, 8, 0, 1, 9, 0, 9, 1, 9, 0, 4, 0, 1, 8, 1, 8, 1, 0, 4, 0, 8, 9, 8, 0, 8, 8, 0, 0, 8, 0, 0, 1, 9, 0, 2, 0, 9, 8, 0, 0, 9, 0, 8, 0, 0, 9, 1, 0, 9, 1, 8, 7, 4, 0, 9, 3, 8, 7, 2, 1, 9, 9, 7, 8, 0, 9, 0, 9, 8, 9, 0, 0, 9, 2, 4, 0, 0, 0, 8, 9, 1, 1, 1, 2, 0, 0, 1, 0, 6, 4, 0, 0, 6, 0, 9, 9, 9, 0, 2, 0, 2, 0, 9, 0, 2, 2, 0, 8, 0, 3, 7, 8, 0, 0, 0, 0, 7, 1, 7, 0, 1, 0, 2, 8, 0, 0, 0, 0, 7, 2, 1, 0, 0, 9, 9, 3, 0, 0, 9, 2, 0, 1, 0, 3, 1, 9, 0, 9, 0, 3, 2, 8, 0, 1, 0, 2, 9, 0, 2, 1, 0, 1, 2, 0, 0, 2, 4, 1, 1, 2, 9, 8, 9, 0, 0, 8, 1, 0, 8, 0, 8, 7, 9, 0, 0, 3, 4, 9, 9, 4, 1, 0, 9, 0, 4, 9, 0, 2, 9, 9, 0, 2, 8, 9, 8, 2, 4, 1, 2, 1, 4, 9, 1, 8, 2, 0, 0, 2, 0, 1, 0, 1, 2, 8, 0, 8, 8, 0, 0, 9, 8, 0, 8, 2, 1, 1, 0, 0, 9, 3, 0, 0, 8, 9, 1, 4, 0, 1, 0, 0, 3, 2, 1, 4, 2, 8, 0, 8, 8, 9, 0, 2, 0, 9, 8, 2, 9, 9, 0, 2, 8, 9, 0, 9, 0, 3, 9, 9, 3, 1, 0, 0, 2, 9, 2, 9, 0, 0, 9, 3, 1, 2, 0, 4, 1, 8, 1, 7, 2, 0, 0, 2, 1, 8, 1, 1, 9, 0, 5, 0, 0, 7, 8, 4, 2, 0, 6, 8, 0, 9, 3, 1, 3, 1, 1, 1, 8, 2, 8, 6, 8, 0, 0, 9, 7, 7, 2, 9, 0, 2, 2, 4, 3, 8, 3, 3, 9, 2, 1, 8, 9, 0, 7, 0, 8, 1, 0, 7, 1, 3, 4, 0, 7, 2, 7, 7, 1, 9, 1, 0, 1, 9, 0, 4, 8, 7, 9, 9, 2, 2, 9, 9, 1, 0, 0, 1, 8, 0, 9, 0, 8, 9, 0, 8, 2, 7, 0, 1, 1, 8, 0, 1, 9, 0, 9, 1, 1, 9, 8, 8, 2, 8, 8, 3, 0, 0, 8, 0, 9, 8, 0, 8, 9, 0, 2, 9, 9, 9, 1, 8, 2, 1, 4, 0, 1, 9, 8, 2, 0, 0, 9, 8, 8, 0, 8, 7, 8, 2, 9, 9, 0, 0, 8, 0, 2, 1, 1, 3, 4, 3, 0, 0, 0, 9, 9, 9, 8, 1, 9, 8, 8, 3, 0, 5, 0, 8, 0, 2, 8, 2, 8, 0, 2, 2, 0, 0, 8, 9, 9, 0, 0, 0, 9, 2, 2, 1, 1, 9, 0, 9, 2, 9, 4, 2, 9, 2, 8, 8, 2, 8, 8, 0, 7, 1, 0, 0, 7, 1, 9, 1, 2, 1, 3, 0, 1, 9, 0, 9, 2, 3, 8, 2, 0, 0, 1, 1, 1, 9, 0, 0, 9, 9, 9, 1, 0, 9, 9, 0, 8, 0, 9, 0, 2, 0, 0, 2, 1, 9, 9, 9, 1, 0, 9, 2, 8, 3, 1, 1, 8, 0, 8, 9, 0, 0, 0, 3, 0, 4, 3, 2, 0, 8, 8, 8, 4, 1, 0, 0, 9, 9, 0, 0, 4, 4, 9, 0, 8, 9, 8, 1, 9, 9, 0, 0, 9, 0, 3, 9, 1, 8, 1, 0, 1, 2, 9, 9, 0, 7, 1, 8, 8, 1, 1, 0, 9, 0, 8, 0, 0, 2, 1, 9, 2, 0, 0, 9, 8, 0, 0, 9, 9, 8, 8, 9, 1, 2, 2, 2, 9, 0, 2, 2, 7, 4, 2, 9, 0, 0, 8, 0, 4, 1, 0, 8, 2, 1, 2, 2, 0, 0, 2, 9, 0, 9, 9, 1, 0, 1, 0, 0, 1, 2, 8, 3, 0, 8, 9, 1, 0, 0, 2, 9, 3, 1, 0, 8, 8, 0, 0, 8, 7, 9, 8, 9, 0, 8, 2, 9, 0, 9, 1, 2, 0, 0, 2, 9, 9, 0, 0, 9, 1, 0, 8, 0, 0, 1, 0, 7, 9, 9, 9, 0, 8, 2, 0, 0, 0, 9, 9, 0, 0, 0, 8, 4, 9, 0, 2, 1, 8, 7, 0, 0, 0, 8, 8, 3, 0, 0, 8, 8, 1, 3, 2, 0, 0, 9, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 9, 9, 4, 9, 1, 1, 2, 0, 3, 0, 0, 9, 0, 0, 9, 0, 1, 9, 0, 0, 7, 0, 3, 2, 2, 9, 3, 9, 0, 0, 0, 8, 0, 0, 9, 9, 2, 8, 0, 0, 0, 9, 1, 7, 1, 0, 0, 1, 0, 0, 0, 9, 1, 1, 8, 9, 7, 9, 9, 0, 1, 0, 1, 0]\n",
            "For  :: airplane  [1, 7, 7, 8, 7, 1, 6, 7, 6, 6, 7, 8, 5, 2, 5, 1, 4, 6, 5, 5, 7, 8, 0, 5, 8, 2, 6, 5, 2, 8, 5, 8, 5, 8, 9, 8, 8, 2, 6, 8, 5, 5, 8, 6, 6, 8, 2, 2, 2, 8, 8, 2, 5, 5, 8, 5, 6, 2, 8, 8, 9, 2, 9, 8, 5, 8, 6, 8, 2, 2, 8, 6, 6, 8, 2, 8, 6, 8, 5, 5, 5, 5, 8, 7, 7, 4, 6, 6, 5, 8, 8, 5, 6, 2, 8, 0, 5, 6, 6, 5, 5, 7, 9, 7, 5, 7, 8, 8, 6, 6, 5, 2, 8, 2, 2, 2, 6, 1, 7, 5, 5, 8, 8, 6, 7, 2, 2, 2, 5, 5, 1, 2, 5, 6, 2, 4, 5, 5, 5, 5, 8, 2, 1, 2, 2, 8, 8, 5, 5, 2, 9, 8, 2, 4, 5, 5, 6, 2, 6, 7, 4, 2, 8, 8, 5, 5, 6, 5, 8, 5, 5, 5, 8, 1, 5, 7, 2, 2, 5, 5, 5, 8, 7, 6, 6, 6, 8, 5, 5, 2, 1, 8, 2, 4, 5, 1, 8, 2, 1, 6, 8, 5, 6, 5, 5, 8, 8, 2, 5, 5, 5, 2, 5, 6, 5, 6, 5, 2, 2, 5, 7, 4, 7, 7, 8, 2, 2, 6, 5, 7, 2, 4, 4, 2, 7, 5, 5, 8, 5, 6, 8, 6, 5, 8, 1, 6, 0, 8, 2, 6, 2, 6, 6, 7, 5, 5, 2, 8, 8, 2, 8, 6, 6, 8, 7, 8, 2, 2, 8, 5, 2, 1, 9, 8, 5, 8, 8, 5, 5, 5, 6, 2, 8, 1, 8, 5, 5, 7, 8, 5, 0, 7, 8, 4, 1, 6, 6, 9, 7, 5, 6, 5, 6, 7, 8, 5, 2, 5, 8, 9, 5, 2, 2, 8, 1, 2, 6, 6, 8, 1, 6, 5, 8, 7, 8, 8, 2, 5, 8, 5, 6, 5, 5, 1, 2, 6, 5, 6, 8, 8, 7, 4, 8, 7, 5, 7, 8, 2, 5, 8, 1, 2, 6, 5, 6, 8, 8, 6, 2, 6, 7, 6, 2, 5, 5, 7, 5, 5, 2, 7, 5, 2, 2, 2, 5, 8, 1, 5, 1, 7, 1, 6, 5, 1, 8, 2, 7, 2, 6, 5, 1, 2, 6, 2, 6, 8, 5, 6, 5, 5, 7, 5, 5, 8, 5, 7, 2, 8, 6, 2, 6, 2, 2, 8, 5, 5, 2, 5, 2, 6, 8, 5, 8, 6, 2, 2, 2, 5, 5, 3, 8, 5, 5, 2, 5, 5, 5, 8, 2, 2, 6, 8, 9, 1, 6, 8, 2, 0, 0, 6, 1, 6, 5, 2, 2, 8, 8, 8, 5, 5, 2, 5, 6, 2, 5, 6, 5, 5, 8, 5, 6, 5, 6, 7, 8, 7, 1, 5, 5, 6, 8, 8, 6, 6, 7, 6, 7, 5, 4, 1, 2, 6, 7, 1, 7, 5, 5, 7, 8, 1, 2, 4, 2, 2, 4, 7, 2, 8, 2, 6, 5, 6, 6, 7, 5, 5, 8, 8, 4, 5, 8, 8, 0, 4, 5, 8, 1, 2, 2, 2, 7, 1, 8, 2, 5, 9, 6, 7, 7, 7, 2, 2, 5, 2, 7, 9, 8, 2, 5, 8, 5, 6, 5, 1, 7, 6, 5, 5, 2, 8, 4, 5, 5, 6, 8, 2, 6, 8, 5, 2, 2, 5, 2, 8, 2, 1, 7, 8, 2, 4, 7, 5, 5, 4, 6, 2, 8, 7, 5, 2, 8, 4, 7, 5, 8, 8, 2, 8, 2, 2, 2, 8, 5, 8, 2, 8, 8, 4, 6, 5, 8, 5, 8, 5, 5, 7, 2, 5, 5, 1, 2, 5, 8, 8, 8, 7, 5, 5, 5, 8, 5, 6, 2, 7, 6, 5, 5, 8, 6, 8, 8, 4, 8, 8, 4, 2, 6, 5, 3, 8, 5, 2, 1, 8, 8, 5, 8, 5, 5, 8, 5, 6, 8, 6, 2, 5, 0, 2, 6, 5, 7, 5, 5, 2, 2, 5, 8, 7, 5, 8, 6, 2, 8, 2, 6, 6, 1, 8, 8, 4, 2, 6, 6, 5, 8, 5, 7, 2, 8, 2, 2, 8, 6, 2, 5, 2, 2, 5, 2, 8, 5, 1, 6, 5, 8, 1, 8, 5, 5, 2, 1, 6, 2, 5, 4, 8, 6, 5, 8, 6, 2, 8, 5, 6, 8, 5, 7, 6, 1, 5, 2, 2, 7, 6, 2, 2, 4, 7, 0, 8, 1, 8, 5, 2, 8, 9, 2, 5, 8, 2, 4, 2, 5, 5, 5, 8, 8, 8, 8, 2, 8, 2, 2, 5, 7, 2, 6, 5, 2, 6, 5, 6, 8, 6, 2, 5, 8, 8, 2, 2, 2, 2, 2, 5, 2, 7, 8, 6, 5, 6, 2, 6, 8, 8, 8, 2, 1, 4, 5, 8, 2, 5, 7, 8, 1, 5, 2, 7, 2, 8, 6, 8, 2, 5, 7, 8, 6, 8, 8, 8, 5, 4, 2, 2, 8, 2, 5, 4, 4, 8, 2, 1, 5, 5, 2, 2, 8, 6, 0, 5, 2, 2, 5, 6, 8, 7, 7, 5, 5, 2, 5, 0, 0, 6, 2, 5, 2, 8, 5, 7, 2, 5, 7, 5, 2, 8, 5, 2, 7, 1, 8, 1, 6, 8, 8, 7, 5, 5, 6, 5, 7, 5, 5, 8, 3, 8, 8, 2, 7, 8, 2, 2, 5, 5, 7, 2, 8, 6, 5, 5, 1, 2, 6, 4, 3, 6, 5, 4, 2, 5, 5, 8, 5, 6, 5, 9, 7, 5, 6, 5, 2, 2, 8, 6, 2, 2, 8, 6, 5, 5, 5, 5, 2, 2, 8, 8, 1, 8, 5, 5, 7, 5, 6, 5, 9, 6, 2, 2, 8, 5, 5, 8, 4, 8, 8, 5, 5, 5, 8, 2, 5, 5, 9, 6, 2, 7, 5, 5, 8, 2, 1, 6, 8, 5, 6, 5, 1, 5, 5, 7, 4, 5, 2, 5, 5, 5, 5, 2, 7, 2]\n",
            "For  :: horse  [2, 8, 2, 2, 8, 2, 1, 1, 4, 1, 2, 4, 2, 8, 8, 2, 2, 2, 4, 2, 5, 4, 0, 2, 8, 2, 8, 2, 2, 2, 6, 5, 9, 2, 2, 4, 8, 2, 2, 2, 2, 2, 2, 8, 9, 7, 7, 9, 8, 2, 7, 1, 4, 2, 3, 2, 4, 7, 2, 0, 1, 2, 4, 2, 9, 2, 4, 4, 2, 2, 5, 4, 2, 4, 2, 2, 2, 4, 4, 8, 4, 2, 2, 8, 9, 5, 2, 8, 2, 9, 4, 5, 7, 8, 9, 2, 8, 7, 4, 1, 8, 2, 2, 2, 9, 1, 2, 2, 4, 1, 8, 1, 2, 2, 2, 7, 8, 2, 3, 4, 4, 2, 2, 1, 2, 2, 4, 4, 1, 2, 4, 2, 8, 2, 4, 2, 4, 2, 2, 8, 8, 2, 4, 2, 9, 9, 5, 8, 2, 2, 2, 2, 4, 1, 4, 4, 2, 9, 1, 1, 5, 2, 1, 1, 2, 2, 2, 2, 2, 4, 3, 8, 5, 2, 2, 2, 2, 2, 2, 5, 9, 4, 2, 2, 2, 2, 2, 8, 2, 2, 4, 8, 2, 2, 2, 2, 2, 2, 2, 2, 8, 9, 5, 7, 8, 1, 8, 2, 2, 2, 0, 8, 2, 4, 2, 2, 0, 2, 6, 2, 6, 2, 9, 2, 7, 1, 4, 2, 2, 2, 9, 4, 4, 2, 2, 4, 4, 8, 2, 8, 8, 8, 9, 2, 7, 1, 2, 2, 2, 2, 2, 2, 2, 4, 8, 2, 2, 2, 2, 2, 1, 8, 1, 1, 4, 2, 2, 8, 8, 8, 9, 1, 8, 7, 7, 4, 9, 7, 2, 4, 4, 4, 2, 2, 4, 2, 1, 2, 4, 4, 1, 8, 2, 2, 2, 1, 1, 4, 7, 1, 6, 2, 1, 2, 2, 9, 2, 2, 1, 9, 2, 0, 4, 2, 2, 1, 2, 8, 0, 2, 2, 4, 2, 2, 2, 2, 0, 2, 4, 6, 5, 9, 2, 9, 0, 2, 2, 2, 2, 2, 8, 4, 2, 1, 4, 2, 9, 4, 1, 8, 4, 2, 9, 1, 2, 1, 2, 8, 2, 2, 8, 2, 4, 7, 8, 2, 2, 2, 7, 4, 4, 1, 1, 9, 4, 1, 7, 4, 9, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 8, 1, 2, 2, 9, 1, 8, 2, 2, 2, 1, 5, 7, 2, 2, 8, 9, 2, 8, 9, 9, 2, 1, 4, 2, 2, 2, 1, 7, 4, 2, 1, 1, 7, 2, 4, 4, 4, 8, 2, 8, 2, 1, 4, 2, 4, 7, 2, 4, 8, 4, 2, 2, 2, 7, 2, 2, 2, 2, 9, 4, 4, 2, 7, 9, 2, 2, 4, 2, 9, 2, 6, 4, 2, 2, 1, 2, 2, 1, 4, 4, 4, 1, 2, 5, 2, 2, 8, 1, 7, 8, 2, 1, 4, 2, 3, 4, 8, 4, 4, 1, 4, 4, 8, 4, 4, 9, 8, 4, 4, 0, 9, 1, 1, 9, 2, 4, 2, 7, 4, 7, 2, 1, 2, 8, 0, 2, 2, 1, 9, 2, 1, 4, 8, 8, 9, 1, 2, 2, 2, 2, 2, 9, 6, 0, 2, 5, 2, 2, 4, 7, 2, 2, 2, 2, 8, 2, 4, 4, 1, 2, 2, 2, 4, 7, 4, 2, 4, 2, 2, 2, 2, 8, 9, 4, 1, 8, 0, 4, 5, 2, 4, 4, 9, 4, 9, 2, 2, 8, 2, 4, 1, 2, 2, 2, 4, 2, 1, 2, 2, 2, 8, 8, 2, 2, 2, 7, 4, 4, 4, 4, 8, 1, 2, 7, 4, 2, 2, 2, 2, 4, 6, 9, 2, 2, 2, 2, 2, 1, 7, 9, 4, 2, 2, 7, 8, 2, 4, 4, 2, 0, 2, 1, 7, 9, 2, 2, 2, 9, 2, 8, 0, 2, 2, 2, 8, 2, 1, 2, 2, 0, 2, 2, 9, 2, 8, 1, 2, 9, 2, 2, 2, 2, 4, 2, 5, 8, 7, 2, 0, 2, 1, 8, 7, 7, 2, 2, 4, 2, 8, 2, 4, 2, 8, 4, 2, 2, 7, 5, 4, 9, 2, 2, 9, 4, 4, 1, 1, 1, 4, 2, 1, 0, 2, 4, 2, 3, 2, 2, 2, 0, 9, 9, 4, 8, 8, 9, 7, 8, 2, 9, 1, 2, 1, 7, 4, 2, 7, 2, 2, 2, 8, 1, 2, 9, 2, 2, 2, 8, 8, 2, 2, 7, 2, 4, 2, 8, 1, 3, 2, 9, 6, 2, 9, 2, 2, 4, 6, 2, 4, 8, 8, 2, 8, 4, 2, 3, 4, 9, 1, 2, 1, 9, 1, 4, 2, 2, 2, 8, 2, 9, 2, 2, 2, 7, 4, 9, 4, 2, 1, 8, 9, 9, 1, 7, 4, 1, 4, 4, 9, 2, 2, 5, 2, 2, 8, 2, 2, 2, 1, 2, 2, 2, 1, 4, 8, 9, 2, 2, 4, 2, 2, 2, 4, 2, 2, 9, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 1, 4, 2, 2, 2, 1, 2, 4, 2, 4, 4, 9, 1, 2, 2, 4, 2, 2, 9, 4, 8, 7, 8, 4, 8, 2, 5, 9, 2, 2, 1, 2, 4, 8, 8, 1, 9, 8, 2, 2, 8, 4, 2, 9, 8, 2, 7, 2, 2, 7, 6, 9, 2, 4, 2, 2, 4, 2, 6, 9, 2, 4, 2, 2, 2, 2, 2, 1, 8, 9, 4, 8, 2, 1, 8, 2, 4, 2, 0, 4, 2, 4, 2, 9, 2, 4, 2, 2, 2, 4, 8, 2, 2, 2, 2, 8, 4, 2, 8, 5, 2, 1, 2, 4, 4, 1, 1, 4, 2, 2, 4, 2, 2, 2, 2, 9, 4, 1, 1, 2, 1, 8, 1, 8, 8, 2, 4, 8, 2, 8, 8, 4, 2, 8, 4, 2, 2, 2, 2, 2, 2, 2, 6, 4, 4, 9, 2, 0, 2, 2, 2, 8, 4, 2, 9, 4, 8, 2, 2, 8, 2, 8, 8, 2]\n",
            "For  :: deer  [3, 3, 8, 3, 7, 7, 2, 3, 4, 7, 4, 7, 1, 3, 7, 2, 1, 2, 7, 4, 3, 1, 4, 7, 4, 3, 8, 6, 4, 9, 7, 6, 2, 1, 3, 1, 3, 3, 7, 7, 3, 7, 3, 7, 7, 7, 4, 7, 4, 7, 4, 1, 3, 3, 7, 7, 2, 1, 7, 4, 4, 2, 7, 2, 3, 4, 1, 4, 7, 3, 3, 1, 7, 8, 0, 9, 7, 3, 4, 8, 7, 9, 4, 7, 1, 7, 1, 7, 7, 4, 3, 1, 1, 2, 4, 3, 5, 3, 8, 4, 7, 3, 8, 7, 8, 7, 7, 3, 7, 7, 5, 7, 7, 5, 4, 7, 8, 2, 7, 7, 3, 8, 2, 2, 7, 1, 1, 4, 8, 4, 3, 7, 4, 4, 3, 8, 7, 3, 4, 3, 7, 1, 4, 7, 3, 3, 3, 7, 4, 0, 8, 4, 4, 3, 4, 4, 3, 7, 9, 7, 7, 9, 3, 3, 7, 4, 7, 7, 2, 8, 3, 2, 4, 0, 3, 7, 4, 7, 3, 8, 3, 4, 4, 2, 0, 2, 5, 2, 7, 3, 7, 7, 7, 9, 4, 5, 7, 7, 4, 3, 5, 2, 4, 3, 1, 7, 9, 3, 9, 4, 5, 3, 4, 7, 3, 7, 4, 0, 4, 1, 3, 3, 8, 3, 3, 4, 5, 4, 3, 8, 3, 1, 7, 3, 4, 1, 5, 4, 3, 3, 2, 1, 2, 3, 2, 9, 1, 4, 4, 4, 4, 3, 9, 4, 1, 4, 8, 7, 7, 3, 1, 4, 5, 3, 5, 9, 7, 3, 3, 4, 3, 2, 7, 9, 2, 1, 2, 7, 1, 7, 1, 7, 2, 7, 3, 4, 9, 4, 4, 7, 4, 7, 3, 7, 7, 5, 7, 1, 5, 8, 5, 1, 3, 4, 8, 4, 7, 7, 3, 7, 8, 9, 3, 7, 2, 1, 7, 3, 7, 2, 2, 7, 9, 4, 3, 8, 3, 0, 7, 5, 7, 7, 2, 3, 3, 4, 3, 1, 7, 9, 7, 4, 7, 3, 4, 4, 3, 3, 9, 3, 7, 3, 4, 7, 3, 1, 1, 5, 4, 7, 3, 3, 7, 7, 3, 4, 9, 1, 7, 7, 4, 9, 0, 1, 4, 2, 2, 4, 7, 3, 9, 7, 2, 1, 4, 7, 1, 4, 4, 3, 4, 7, 7, 1, 7, 3, 3, 1, 3, 9, 3, 7, 7, 2, 4, 4, 7, 4, 7, 7, 7, 3, 5, 3, 7, 7, 7, 3, 4, 8, 7, 4, 3, 4, 2, 3, 4, 4, 3, 4, 3, 3, 7, 4, 7, 7, 3, 7, 7, 3, 4, 0, 7, 2, 3, 4, 7, 3, 7, 4, 7, 7, 1, 4, 3, 8, 4, 7, 4, 4, 7, 4, 4, 2, 3, 2, 4, 3, 7, 1, 3, 7, 3, 7, 4, 8, 7, 1, 8, 9, 4, 4, 0, 7, 4, 7, 7, 8, 3, 3, 2, 4, 0, 1, 9, 7, 7, 7, 4, 4, 2, 4, 1, 7, 4, 3, 3, 3, 4, 8, 7, 7, 3, 8, 7, 4, 7, 1, 3, 7, 4, 4, 2, 4, 4, 2, 3, 8, 7, 1, 8, 7, 8, 7, 8, 0, 4, 7, 4, 9, 7, 1, 4, 8, 1, 4, 2, 2, 3, 3, 8, 7, 4, 7, 4, 2, 0, 3, 7, 7, 7, 9, 3, 3, 2, 2, 4, 4, 2, 7, 7, 7, 6, 3, 7, 4, 7, 7, 4, 3, 3, 7, 3, 8, 7, 7, 7, 3, 1, 7, 1, 7, 7, 1, 7, 7, 4, 3, 3, 3, 7, 4, 1, 3, 3, 4, 3, 7, 7, 1, 3, 8, 7, 7, 7, 3, 4, 3, 3, 9, 7, 7, 6, 8, 1, 4, 3, 7, 4, 4, 9, 7, 7, 1, 7, 1, 7, 3, 4, 3, 1, 3, 7, 7, 3, 9, 2, 7, 7, 3, 7, 5, 4, 3, 1, 7, 7, 4, 7, 9, 4, 4, 1, 9, 3, 7, 7, 7, 3, 7, 7, 4, 7, 7, 9, 6, 2, 4, 7, 5, 1, 4, 4, 3, 7, 5, 7, 7, 7, 4, 1, 4, 3, 9, 2, 1, 0, 7, 7, 2, 2, 3, 9, 4, 3, 3, 8, 7, 7, 4, 4, 7, 3, 7, 5, 0, 3, 8, 4, 3, 7, 7, 8, 1, 7, 7, 1, 7, 7, 4, 1, 8, 1, 9, 7, 3, 8, 4, 0, 8, 3, 7, 7, 7, 7, 7, 1, 7, 7, 3, 1, 3, 4, 8, 4, 7, 4, 3, 4, 7, 4, 2, 4, 4, 7, 7, 3, 4, 0, 3, 8, 8, 2, 7, 7, 4, 3, 2, 4, 4, 3, 3, 7, 8, 7, 1, 7, 4, 4, 7, 7, 9, 3, 4, 4, 1, 9, 3, 4, 3, 9, 3, 7, 4, 2, 2, 1, 7, 2, 4, 4, 0, 4, 4, 3, 4, 4, 8, 7, 4, 4, 7, 3, 7, 4, 4, 3, 7, 5, 4, 7, 4, 4, 3, 7, 7, 9, 4, 8, 1, 3, 7, 3, 4, 7, 7, 2, 2, 3, 8, 7, 3, 3, 3, 8, 7, 4, 8, 4, 3, 3, 7, 8, 7, 7, 9, 1, 7, 4, 3, 5, 3, 3, 3, 3, 7, 4, 3, 8, 3, 3, 5, 4, 7, 7, 3, 7, 7, 7, 7, 7, 8, 7, 4, 3, 3, 7, 8, 1, 3, 1, 7, 7, 1, 4, 8, 1, 1, 7, 2, 1, 4, 7, 7, 2, 2, 7, 1, 4, 3, 7, 7, 4, 2, 7, 7, 4, 7, 7, 7, 7, 2, 4, 4, 3, 7, 4, 7, 4, 3, 7, 3, 4, 3, 8, 7, 8, 5, 7, 2, 7, 7, 7, 3, 5, 7, 7, 3, 7, 4, 3, 1, 3, 3, 4, 8, 3, 4, 3, 4, 8, 2, 8, 7, 7, 3, 8, 3, 3, 4, 4, 4, 7, 2, 3, 4, 9, 7, 8, 4, 1, 4, 8, 7, 4, 4, 4, 7, 8, 3]\n",
            "For  :: truck  [2, 4, 5, 6, 4, 2, 0, 8, 4, 4, 6, 4, 2, 5, 8, 5, 2, 2, 4, 4, 6, 6, 6, 6, 6, 4, 4, 5, 4, 2, 2, 8, 5, 2, 6, 4, 4, 6, 2, 4, 4, 0, 2, 8, 8, 4, 8, 4, 4, 6, 6, 8, 8, 4, 5, 6, 6, 8, 8, 6, 8, 4, 6, 8, 5, 4, 6, 4, 2, 4, 4, 6, 8, 2, 4, 2, 8, 2, 4, 9, 5, 6, 2, 2, 5, 4, 4, 6, 9, 6, 2, 4, 5, 5, 1, 2, 8, 4, 8, 2, 6, 8, 4, 6, 4, 2, 4, 6, 6, 2, 5, 8, 1, 4, 5, 2, 2, 7, 5, 5, 2, 4, 8, 4, 2, 6, 6, 8, 4, 8, 4, 8, 7, 2, 2, 2, 4, 5, 0, 4, 2, 4, 2, 0, 6, 2, 4, 6, 5, 4, 6, 8, 6, 6, 5, 4, 2, 8, 2, 2, 2, 6, 5, 4, 4, 2, 8, 2, 8, 4, 4, 6, 6, 4, 8, 4, 2, 6, 6, 2, 5, 8, 8, 4, 4, 4, 2, 2, 4, 1, 4, 4, 6, 4, 6, 4, 6, 8, 2, 6, 5, 8, 6, 4, 4, 2, 2, 2, 4, 4, 2, 4, 0, 6, 4, 6, 8, 8, 6, 2, 8, 4, 6, 8, 2, 2, 0, 4, 2, 4, 4, 2, 4, 1, 8, 2, 2, 8, 2, 2, 2, 8, 2, 1, 2, 2, 2, 6, 2, 8, 6, 6, 2, 2, 6, 4, 4, 6, 6, 6, 2, 2, 4, 2, 2, 8, 2, 2, 6, 8, 2, 5, 4, 2, 6, 4, 8, 5, 2, 2, 6, 4, 5, 2, 4, 4, 4, 6, 6, 5, 8, 8, 4, 5, 2, 8, 2, 8, 6, 2, 4, 4, 1, 2, 5, 2, 7, 6, 6, 4, 5, 5, 8, 2, 2, 8, 8, 6, 4, 2, 4, 5, 8, 9, 4, 5, 5, 4, 6, 6, 8, 4, 2, 6, 2, 6, 2, 1, 8, 5, 6, 8, 5, 4, 4, 2, 2, 6, 5, 4, 4, 4, 4, 6, 6, 6, 2, 2, 2, 8, 4, 6, 5, 6, 8, 2, 2, 0, 4, 5, 6, 8, 2, 2, 4, 4, 2, 6, 2, 2, 0, 2, 5, 2, 8, 2, 2, 2, 2, 4, 4, 4, 1, 2, 2, 4, 2, 4, 5, 2, 6, 2, 8, 8, 4, 5, 4, 5, 6, 4, 5, 5, 2, 6, 2, 5, 0, 2, 6, 4, 1, 4, 4, 4, 5, 0, 4, 6, 8, 6, 2, 5, 4, 8, 6, 6, 6, 2, 8, 5, 4, 2, 5, 8, 5, 8, 6, 5, 2, 5, 8, 8, 1, 2, 4, 2, 2, 5, 6, 4, 4, 7, 4, 2, 2, 2, 8, 2, 4, 2, 8, 1, 6, 6, 2, 2, 2, 4, 2, 6, 8, 2, 4, 4, 2, 8, 6, 6, 4, 1, 8, 8, 8, 5, 4, 4, 1, 2, 6, 2, 6, 2, 4, 2, 2, 4, 2, 8, 5, 6, 6, 2, 8, 8, 6, 6, 9, 8, 6, 5, 8, 8, 5, 5, 2, 4, 5, 5, 4, 4, 2, 8, 2, 2, 2, 1, 6, 2, 8, 2, 6, 8, 4, 4, 8, 2, 5, 2, 4, 4, 8, 2, 5, 4, 2, 5, 6, 8, 6, 8, 6, 6, 2, 4, 8, 5, 2, 6, 5, 4, 6, 6, 2, 5, 6, 6, 6, 6, 2, 6, 2, 6, 7, 2, 2, 6, 8, 6, 4, 5, 6, 4, 4, 5, 6, 5, 2, 4, 6, 4, 2, 2, 4, 2, 2, 6, 8, 4, 8, 2, 2, 8, 2, 2, 2, 4, 5, 5, 4, 2, 6, 8, 2, 4, 6, 4, 6, 4, 2, 6, 2, 2, 6, 2, 5, 2, 8, 6, 6, 8, 2, 2, 2, 2, 8, 8, 6, 2, 6, 5, 5, 4, 6, 5, 4, 5, 2, 6, 6, 6, 6, 2, 4, 2, 6, 5, 2, 5, 1, 2, 8, 2, 6, 2, 4, 6, 2, 8, 2, 2, 5, 4, 5, 6, 0, 2, 2, 4, 2, 6, 5, 4, 6, 4, 4, 2, 4, 4, 6, 8, 6, 6, 6, 2, 6, 5, 4, 5, 4, 5, 8, 2, 8, 6, 4, 0, 6, 5, 4, 4, 2, 6, 4, 6, 2, 2, 5, 2, 5, 2, 8, 6, 2, 6, 4, 4, 6, 2, 8, 6, 4, 4, 8, 2, 5, 6, 4, 6, 6, 2, 2, 4, 8, 6, 8, 2, 4, 4, 2, 6, 6, 2, 2, 2, 2, 5, 8, 4, 8, 2, 6, 8, 8, 6, 2, 4, 6, 5, 2, 4, 5, 2, 6, 2, 8, 2, 4, 8, 6, 2, 8, 2, 2, 2, 6, 2, 4, 4, 8, 4, 2, 6, 8, 2, 8, 4, 7, 4, 5, 4, 4, 6, 8, 6, 4, 5, 2, 2, 8, 8, 5, 2, 4, 6, 5, 6, 5, 4, 2, 4, 6, 2, 2, 8, 4, 1, 9, 4, 2, 2, 4, 6, 6, 5, 2, 4, 5, 6, 2, 2, 5, 8, 2, 1, 0, 4, 6, 8, 2, 2, 5, 6, 2, 2, 2, 2, 4, 5, 8, 4, 2, 2, 6, 6, 4, 6, 5, 2, 5, 2, 6, 4, 2, 4, 6, 8, 4, 5, 2, 2, 5, 2, 5, 4, 5, 7, 2, 2, 5, 2, 4, 5, 8, 7, 8, 8, 5, 6, 5, 6, 2, 8, 8, 6, 8, 6, 4, 6, 5, 2, 2, 2, 2, 8, 2, 2, 2, 8, 6, 4, 2, 6, 2, 8, 6, 2, 5, 0, 2, 5, 6, 6, 2, 6, 4, 6, 0, 4, 6, 2, 2, 5, 2, 8, 2, 2, 2, 2, 6, 8, 8, 5, 2, 8, 5, 8, 4, 6, 6, 2, 2, 4, 6, 2, 2, 2, 6, 4, 6, 6, 2, 5, 4, 4, 6, 8, 2, 2, 4, 6, 6, 2, 2, 4, 4, 5, 8, 4, 8, 2]\n",
            "For  :: automobile  [5, 2, 6, 2, 4, 8, 2, 6, 6, 2, 6, 8, 2, 2, 2, 6, 6, 6, 2, 5, 1, 2, 5, 9, 6, 2, 6, 2, 6, 6, 4, 6, 6, 4, 5, 5, 2, 4, 6, 5, 2, 9, 4, 2, 2, 2, 6, 2, 2, 0, 4, 8, 6, 5, 8, 1, 4, 5, 4, 8, 4, 4, 2, 6, 8, 4, 5, 2, 2, 4, 5, 6, 2, 2, 4, 4, 4, 2, 4, 8, 8, 2, 4, 6, 6, 6, 6, 8, 7, 4, 8, 2, 6, 6, 2, 6, 4, 4, 4, 1, 8, 9, 6, 2, 5, 5, 6, 8, 2, 4, 8, 2, 2, 4, 2, 2, 4, 2, 6, 4, 1, 4, 2, 8, 6, 6, 4, 4, 2, 2, 2, 8, 6, 2, 8, 9, 5, 4, 4, 8, 5, 2, 5, 6, 8, 1, 7, 5, 2, 6, 4, 4, 4, 2, 5, 5, 8, 2, 4, 6, 4, 6, 4, 4, 5, 4, 2, 5, 5, 6, 4, 8, 2, 2, 2, 7, 5, 2, 5, 2, 2, 8, 6, 4, 2, 6, 2, 4, 4, 5, 6, 4, 4, 8, 8, 4, 2, 7, 4, 2, 2, 4, 4, 4, 2, 6, 2, 8, 2, 2, 6, 4, 0, 6, 5, 8, 6, 4, 4, 6, 5, 6, 8, 5, 9, 2, 6, 6, 0, 2, 2, 2, 2, 6, 5, 4, 6, 8, 6, 6, 5, 4, 2, 4, 6, 4, 2, 4, 2, 4, 5, 4, 4, 2, 2, 4, 4, 6, 4, 6, 4, 4, 1, 4, 6, 4, 6, 6, 4, 4, 5, 2, 4, 6, 6, 6, 5, 2, 5, 2, 4, 4, 6, 6, 6, 4, 4, 5, 6, 6, 5, 4, 4, 2, 8, 8, 2, 4, 2, 6, 4, 8, 6, 6, 8, 8, 8, 2, 4, 2, 2, 0, 4, 8, 5, 5, 8, 2, 2, 8, 2, 5, 4, 5, 1, 2, 2, 6, 8, 4, 4, 6, 6, 4, 8, 4, 2, 1, 2, 6, 6, 4, 6, 8, 8, 6, 8, 2, 2, 2, 5, 6, 4, 2, 6, 6, 0, 6, 5, 8, 6, 8, 2, 8, 2, 5, 7, 2, 2, 6, 6, 2, 2, 8, 2, 6, 5, 1, 1, 2, 2, 9, 2, 7, 4, 5, 4, 2, 8, 5, 4, 6, 4, 2, 6, 4, 4, 2, 5, 2, 4, 2, 4, 5, 4, 6, 5, 4, 5, 2, 2, 8, 5, 8, 6, 4, 5, 2, 6, 2, 6, 6, 5, 6, 4, 4, 2, 4, 4, 5, 4, 4, 6, 4, 5, 5, 2, 4, 2, 5, 2, 6, 4, 4, 2, 2, 5, 4, 7, 6, 1, 4, 4, 4, 2, 7, 5, 6, 4, 2, 2, 4, 6, 1, 5, 6, 4, 5, 7, 5, 5, 5, 8, 4, 6, 8, 7, 8, 9, 5, 6, 8, 4, 4, 5, 6, 5, 5, 6, 6, 2, 0, 5, 8, 1, 2, 2, 4, 6, 9, 2, 4, 2, 2, 4, 2, 0, 0, 5, 2, 8, 1, 4, 2, 4, 8, 4, 2, 2, 4, 2, 2, 8, 2, 6, 4, 6, 4, 6, 5, 6, 4, 2, 2, 4, 8, 6, 2, 6, 4, 6, 4, 4, 4, 8, 9, 6, 4, 2, 4, 4, 6, 2, 6, 5, 5, 2, 8, 8, 2, 2, 2, 4, 7, 6, 6, 2, 8, 1, 2, 2, 6, 4, 4, 2, 6, 4, 5, 5, 2, 4, 6, 2, 2, 2, 4, 4, 1, 4, 5, 2, 8, 4, 5, 6, 4, 6, 4, 9, 8, 2, 8, 4, 2, 2, 4, 8, 7, 5, 4, 6, 4, 5, 2, 4, 4, 4, 2, 4, 8, 4, 2, 1, 1, 7, 5, 4, 6, 6, 8, 6, 4, 4, 2, 6, 2, 4, 4, 2, 2, 6, 5, 2, 8, 2, 5, 5, 8, 5, 8, 5, 4, 2, 4, 6, 4, 5, 6, 4, 4, 7, 2, 1, 2, 2, 2, 5, 2, 4, 6, 8, 4, 5, 2, 4, 6, 2, 5, 4, 6, 4, 4, 2, 2, 8, 4, 2, 8, 6, 2, 2, 2, 4, 9, 6, 2, 2, 4, 6, 7, 6, 2, 4, 8, 4, 1, 8, 4, 8, 4, 4, 5, 6, 6, 0, 6, 4, 2, 4, 4, 4, 6, 2, 4, 4, 5, 5, 8, 2, 2, 5, 2, 7, 1, 2, 5, 4, 2, 2, 8, 6, 2, 2, 2, 2, 4, 4, 4, 5, 6, 2, 6, 4, 1, 2, 6, 6, 2, 2, 2, 8, 4, 2, 4, 7, 2, 4, 5, 5, 6, 6, 2, 6, 4, 2, 4, 4, 6, 2, 8, 6, 1, 2, 5, 8, 4, 4, 4, 5, 5, 2, 2, 8, 4, 2, 6, 5, 6, 2, 8, 6, 6, 2, 2, 6, 9, 2, 4, 6, 2, 4, 6, 6, 2, 4, 6, 2, 4, 4, 4, 6, 2, 2, 4, 5, 6, 2, 5, 4, 6, 5, 6, 2, 2, 2, 7, 5, 2, 2, 8, 4, 4, 8, 8, 2, 6, 2, 2, 5, 5, 2, 4, 6, 4, 4, 4, 8, 6, 4, 2, 1, 9, 6, 5, 4, 2, 4, 2, 4, 4, 4, 4, 9, 2, 4, 2, 6, 5, 6, 2, 4, 2, 2, 2, 6, 2, 2, 6, 6, 5, 2, 2, 2, 8, 4, 1, 2, 2, 5, 2, 5, 6, 6, 0, 2, 2, 0, 6, 5, 6, 6, 2, 4, 6, 2, 5, 2, 8, 2, 5, 2, 8, 6, 2, 6, 2, 4, 2, 4, 5, 6, 2, 2, 4, 5, 4, 4, 5, 2, 5, 6, 2, 5, 2, 2, 2, 4, 5, 6, 4, 5, 5, 4, 5, 2, 8, 4, 2, 2, 2, 7, 4, 2, 2, 8, 2, 4, 5, 2, 5, 4, 6, 4, 5, 4, 8, 5, 6, 5, 1, 2, 6, 2, 2, 2, 4, 6, 6, 1, 4, 4, 2, 2, 4, 6, 5, 8, 6, 6, 8]\n",
            "For  :: dog  [0, 9, 0, 0, 7, 1, 2, 0, 1, 0, 7, 0, 9, 0, 9, 2, 9, 0, 1, 0, 0, 9, 9, 4, 0, 9, 7, 7, 0, 2, 0, 2, 7, 0, 9, 0, 0, 1, 9, 0, 4, 0, 9, 8, 9, 0, 1, 1, 0, 8, 7, 9, 4, 4, 9, 1, 2, 9, 0, 2, 8, 8, 0, 7, 4, 1, 3, 0, 8, 0, 1, 0, 0, 9, 2, 9, 8, 0, 1, 2, 8, 9, 2, 9, 4, 1, 4, 2, 0, 9, 2, 0, 2, 0, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 8, 2, 1, 2, 9, 0, 0, 2, 0, 0, 9, 2, 2, 0, 0, 9, 9, 2, 9, 2, 9, 9, 9, 0, 2, 9, 0, 8, 7, 9, 4, 9, 1, 7, 7, 2, 0, 8, 2, 0, 8, 1, 0, 1, 9, 9, 0, 8, 1, 7, 8, 3, 0, 8, 0, 1, 2, 7, 9, 2, 1, 0, 7, 7, 0, 0, 2, 4, 2, 7, 8, 9, 0, 9, 3, 9, 3, 0, 0, 3, 8, 8, 9, 9, 9, 8, 0, 8, 7, 9, 2, 8, 0, 2, 0, 0, 0, 0, 9, 9, 9, 1, 2, 2, 0, 9, 2, 1, 8, 1, 2, 7, 0, 9, 2, 2, 1, 2, 0, 4, 7, 2, 0, 2, 9, 0, 9, 4, 7, 8, 7, 0, 3, 8, 9, 8, 8, 0, 9, 0, 2, 1, 1, 8, 2, 2, 7, 1, 9, 0, 0, 8, 0, 9, 2, 2, 8, 7, 0, 9, 9, 9, 1, 1, 8, 8, 0, 3, 0, 9, 0, 7, 9, 8, 1, 4, 0, 0, 1, 2, 4, 9, 0, 9, 0, 3, 9, 2, 1, 9, 9, 2, 9, 0, 1, 8, 9, 2, 1, 9, 8, 0, 2, 7, 2, 1, 9, 0, 0, 9, 0, 1, 1, 0, 2, 0, 2, 8, 9, 7, 7, 9, 9, 0, 1, 5, 2, 8, 2, 9, 1, 0, 1, 0, 0, 1, 7, 9, 9, 0, 7, 2, 2, 2, 0, 0, 9, 1, 7, 9, 2, 0, 8, 8, 0, 8, 9, 4, 2, 8, 1, 9, 0, 9, 0, 0, 0, 0, 2, 1, 9, 7, 1, 1, 9, 0, 0, 3, 3, 9, 2, 7, 2, 0, 9, 2, 8, 2, 8, 2, 0, 0, 9, 0, 1, 1, 9, 8, 1, 0, 5, 0, 9, 9, 1, 2, 8, 2, 9, 4, 9, 5, 8, 1, 9, 1, 8, 8, 0, 8, 1, 9, 1, 8, 1, 2, 1, 1, 1, 8, 0, 4, 2, 2, 0, 7, 2, 0, 2, 2, 2, 0, 1, 9, 8, 0, 4, 0, 1, 1, 0, 0, 8, 9, 7, 0, 9, 3, 9, 2, 7, 0, 2, 9, 2, 0, 9, 2, 2, 0, 2, 1, 8, 0, 0, 0, 0, 9, 2, 7, 2, 9, 9, 9, 1, 8, 7, 7, 1, 4, 7, 8, 7, 2, 0, 0, 1, 8, 2, 2, 1, 7, 0, 8, 9, 9, 7, 0, 9, 8, 7, 9, 9, 8, 2, 7, 7, 9, 2, 0, 2, 2, 0, 0, 2, 2, 3, 9, 0, 2, 4, 2, 0, 1, 2, 7, 0, 0, 8, 8, 7, 1, 9, 2, 0, 2, 0, 1, 0, 4, 0, 0, 1, 2, 7, 1, 1, 9, 2, 1, 2, 1, 2, 8, 0, 9, 1, 0, 9, 7, 2, 1, 0, 9, 2, 0, 2, 9, 9, 1, 0, 4, 2, 8, 3, 9, 9, 9, 0, 9, 4, 0, 0, 0, 9, 0, 8, 2, 9, 9, 9, 9, 1, 9, 0, 0, 4, 1, 0, 7, 2, 9, 8, 8, 0, 1, 7, 9, 1, 8, 0, 8, 0, 0, 1, 7, 9, 0, 1, 2, 8, 0, 9, 1, 7, 4, 8, 4, 9, 7, 0, 9, 1, 0, 1, 7, 9, 9, 9, 7, 8, 2, 0, 9, 1, 0, 0, 7, 9, 4, 2, 2, 2, 0, 0, 2, 2, 7, 0, 9, 9, 1, 0, 0, 0, 4, 0, 9, 3, 7, 0, 1, 2, 0, 9, 2, 7, 2, 0, 0, 7, 9, 2, 8, 9, 4, 9, 9, 1, 2, 8, 7, 8, 9, 2, 9, 2, 0, 0, 9, 0, 8, 0, 2, 9, 0, 0, 1, 9, 9, 9, 0, 8, 8, 1, 9, 9, 9, 0, 0, 9, 2, 9, 8, 8, 9, 8, 8, 1, 9, 0, 0, 9, 0, 0, 2, 0, 7, 2, 9, 0, 7, 1, 1, 0, 9, 0, 0, 0, 8, 0, 2, 2, 9, 7, 8, 1, 4, 1, 0, 0, 7, 3, 0, 0, 9, 4, 0, 8, 2, 7, 2, 2, 1, 2, 0, 8, 1, 7, 4, 0, 1, 2, 9, 2, 9, 9, 9, 9, 2, 2, 0, 4, 8, 2, 0, 7, 0, 9, 7, 9, 7, 1, 9, 9, 7, 0, 9, 8, 0, 8, 2, 1, 7, 8, 9, 0, 8, 1, 9, 2, 0, 1, 7, 1, 0, 2, 2, 1, 9, 9, 9, 1, 2, 0, 0, 9, 4, 8, 1, 4, 8, 8, 9, 0, 2, 0, 1, 4, 8, 7, 9, 2, 1, 2, 3, 2, 0, 8, 2, 2, 1, 9, 1, 9, 9, 0, 1, 9, 9, 8, 4, 2, 0, 0, 9, 0, 4, 4, 7, 9, 8, 0, 8, 2, 8, 2, 2, 0, 0, 0, 0, 9, 9, 1, 2, 0, 2, 4, 8, 9, 0, 9, 0, 0, 0, 0, 7, 8, 2, 2, 9, 0, 4, 0, 1, 0, 9, 9, 2, 1, 0, 2, 2, 9, 9, 7, 0, 0, 9, 9, 2, 9, 0, 7, 8, 7, 9, 7, 9, 7, 0, 1, 8, 7, 9, 8, 8, 2, 8, 0, 2, 2, 9, 2, 4, 9, 7, 4, 8, 8, 7, 0, 2, 9, 7, 0, 7, 2, 0, 0, 1, 9, 4, 9, 4, 7, 9, 8, 9, 0, 0, 2, 2, 0, 2]\n",
            "embedding for all classes found now stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m73ipJcrDSgA",
        "outputId": "e3cbdd3e-a96c-470d-9cbd-4cf7ac2cf5f3"
      },
      "source": [
        "import statistics \n",
        "\n",
        "mapping = {}\n",
        "\n",
        "classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "\n",
        "for i in kmeans_labels_dict:\n",
        "  \n",
        "  print(i , statistics.mode(kmeans_labels_dict[i]))\n",
        "\n",
        "  mapping[statistics.mode(kmeans_labels_dict[i])] = classes.index(i)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frog 2\n",
            "truck 2\n",
            "deer 7\n",
            "automobile 2\n",
            "bird 9\n",
            "horse 2\n",
            "ship 2\n",
            "cat 0\n",
            "dog 0\n",
            "airplane 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEnF-ZSpDRsi",
        "outputId": "b950a48f-2190-4ad5-95a9-db00418d45da"
      },
      "source": [
        "mapping "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5, 2: 8, 5: 0, 7: 4, 9: 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb-SjvRbDRe4",
        "outputId": "3421f3d1-a779-44fe-bce6-c56071ba6613"
      },
      "source": [
        "from collections import Counter\n",
        "for c_ in ['airplane','ship']:\n",
        "  print(f'for {c_} most occuring  top 3 classes are : {Counter(kmeans_labels_dict[c_]).most_common(3)}')\n",
        "\n",
        "# now the possiable classes for cat and dog are "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for airplane most occuring  top 3 classes are : [(5, 260), (8, 207), (2, 196)]\n",
            "for ship most occuring  top 3 classes are : [(2, 202), (6, 184), (5, 165)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DEiF94RDjCs",
        "outputId": "e7417716-1570-4bdb-f69b-136effd2d453"
      },
      "source": [
        "mapping[7] = classes.index('airplane')\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5, 2: 8, 5: 0, 7: 0, 9: 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "PmHXmERxDkJz",
        "outputId": "74743b90-fe0f-4fa6-b6c1-4ebe12fb04f6"
      },
      "source": [
        "#mapping \n",
        "preds = kModel.labels_\n",
        "print(\"mapped for preds\")\n",
        "mapped_pred_labels = []\n",
        "\n",
        "print(mapping)\n",
        "\n",
        "print(len(preds))\n",
        "\n",
        "for pred in preds: \n",
        "  mapped_pred_labels.append(mapping[pred]) \n",
        "\n",
        "len(mapped_pred_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mapped for preds\n",
            "{2: 8, 7: 0, 9: 2, 0: 5, 5: 0}\n",
            "49664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-77623bfba0a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mmapped_pred_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_pred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 4"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98qCXB-6DpVY",
        "outputId": "77aee981-ff72-48b5-aee7-a2febc19a085"
      },
      "source": [
        "true_labels[10:21],preds[10:21],mapped_pred_labels[10:21]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor(4),\n",
              "  tensor(7),\n",
              "  tensor(7),\n",
              "  tensor(2),\n",
              "  tensor(9),\n",
              "  tensor(9),\n",
              "  tensor(9),\n",
              "  tensor(3),\n",
              "  tensor(2),\n",
              "  tensor(6),\n",
              "  tensor(4)],\n",
              " array([3, 8, 2, 1, 5, 6, 4, 0, 2, 0, 8], dtype=int32),\n",
              " [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "rx_F1LoMDqS0",
        "outputId": "53194b68-6ad1-439d-83f2-962e2525bdc9"
      },
      "source": [
        "# testing the accuracy with the real ground truth \n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(mapped_pred_labels,true_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-55667919f5ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# testing the accuracy with the real ground truth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped_pred_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 49664]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLxSlCa-6zTi"
      },
      "source": [
        "!python /content/Unsupervised-Classification/eval.py --config_exp /content/Unsupervised-Classification/configs/selflabel/selflabel_cifar10.yml --model /content/drive/MyDrive/SCAN/selflabel_cifar-10.pth.tar --visualize_prototypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I1fPiI-DAIl",
        "outputId": "147e8375-0ed3-43cf-dc7f-1e7ecf39aed3"
      },
      "source": [
        "from models.models import ClusteringModel\n",
        "from models.resnet_cifar import resnet18\n",
        "\n",
        "state_dict = torch.load('/content/drive/MyDrive/SCAN/scan_cifar-10.pth.tar')\n",
        "\n",
        "state_dict['model'].keys()\n",
        "\n",
        "backbone = resnet18()\n",
        "model = ClusteringModel(backbone, 10, 1)\n",
        "model.load_state_dict(state_dict['model'])\n",
        "model = model.cuda()\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClusteringModel(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (cluster_head): ModuleList(\n",
              "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUKaxUEwDAko",
        "outputId": "11eb2132-7ded-4d0f-bbd3-7fdc0691237a"
      },
      "source": [
        "data_file = {'gt':[],'pred':[],'className':[]}\n",
        "\n",
        "for data in tqdm(train_dataloader):\n",
        "    data_file['gt'].extend(data['target'].numpy())\n",
        "    data_file['className'].extend(data['meta']['class_name'])\n",
        "    data_file['pred'].extend(torch.argmax(model(data['image'].cuda())[0],dim = 1).cpu().detach().numpy())\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/98 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|| 98/98 [00:10<00:00,  9.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drrtax2fDAwW",
        "outputId": "01cf0064-d39e-41ce-fc28-df2d27b6a3b9"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "'''\n",
        "keys are the  preds and values are the gt. \n",
        "\n",
        "we will be mapping the preds to gt targets.\n",
        "\n",
        "'''\n",
        "\n",
        "df = pd.DataFrame(data_file)\n",
        "\n",
        "gp = df.groupby('gt')\n",
        "\n",
        "vals = gp.aggregate(statistics.mode).iloc[:,0:-1]\n",
        "\n",
        "mapping = { j[0]:i  for i,j in zip(list(vals.index),vals.values)}\n",
        "\n",
        "# for i,j in zip(list(vals.index),vals.values):\n",
        "\n",
        "#   print(i,j)\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 6, 1: 0, 2: 8, 3: 9, 4: 4, 5: 5, 6: 7, 7: 1, 8: 2, 9: 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2eTHRQ47Hwd",
        "outputId": "8b91b992-e4ad-4590-80b9-b5f57535c1bd"
      },
      "source": [
        "df['mapped_preds'] = df['pred'].map(lambda x : mapping[x])\n",
        "\n",
        "# df[['gt','mapped_preds']]    \n",
        "accuracy_score(df['gt'].values,df['mapped_preds'].values)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-23QRBLXJ4W4",
        "outputId": "1a503fbb-1c6d-4bf8-fef8-4126bebe7724"
      },
      "source": [
        "from utils.common_config import get_val_dataset\n",
        "\n",
        "#for evaluating will be only using the get_val_transforms\n",
        "test_transformations = get_val_transformations(p)\n",
        "test_dataset = get_val_dataset(p, test_transformations)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, num_workers=4,batch_size=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv6d2GbhJ7Qs",
        "outputId": "80558072-657e-48b2-f9b6-a0d73aff1bd1"
      },
      "source": [
        "data_file = {'gt':[],'pred':[],'className':[]}\n",
        "\n",
        "# get preds \n",
        "\n",
        "for data in tqdm(test_dataloader):\n",
        "    data_file['gt'].extend(data['target'].numpy())\n",
        "    data_file['className'].extend(data['meta']['class_name'])\n",
        "    data_file['pred'].extend(torch.argmax(model(data['image'].cuda())[0],dim = 1).cpu().detach().numpy())\n",
        "    \n",
        "\n",
        "\n",
        "# create mapping \n",
        "\n",
        "df = pd.DataFrame(data_file)\n",
        "gp = df.groupby('gt')\n",
        "vals = gp.aggregate(statistics.mode).iloc[:,0:-1]\n",
        "mapping = { j[0]:i  for i,j in zip(list(vals.index),vals.values)}\n",
        "print('mappingn',mapping)\n",
        "\n",
        "\n",
        "#mapping\n",
        "\n",
        "df['mapped_preds'] = df['pred'].map(lambda x : mapping[x])\n",
        "\n",
        "# df[['gt','mapped_preds']]    \n",
        "\n",
        "\n",
        "print('test-acc :',accuracy_score(df['gt'].values,df['mapped_preds'].values))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|| 20/20 [00:02<00:00,  8.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mappingn {1: 0, 7: 1, 8: 2, 9: 3, 4: 4, 5: 5, 0: 6, 6: 7, 2: 8, 3: 9}\n",
            "test-acc : 0.8161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgjCeHsLJ9io",
        "outputId": "1fa4aa2c-8fa7-4533-c762-e2d13c9d2082"
      },
      "source": [
        "from models.models import ClusteringModel\n",
        "from models.resnet_cifar import resnet18\n",
        "\n",
        "\n",
        "state_dict = torch.load('/content/drive/MyDrive/SCAN/selflabel_cifar-10.pth.tar')\n",
        "\n",
        "# state_dict['model'].keys()\n",
        "\n",
        "backbone = resnet18()\n",
        "model = ClusteringModel(backbone, 10, 1)\n",
        "model.load_state_dict(state_dict)\n",
        "model = model.cuda()\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClusteringModel(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (shortcut): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (cluster_head): ModuleList(\n",
              "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR2BnX68KJrq",
        "outputId": "9e8123be-3ca6-4dea-a8ad-7b2094f524ba"
      },
      "source": [
        "data_file = {'gt':[],'pred':[],'className':[]}\n",
        "\n",
        "for data in tqdm(train_dataloader):\n",
        "    data_file['gt'].extend(data['target'].numpy())\n",
        "    data_file['className'].extend(data['meta']['class_name'])\n",
        "    data_file['pred'].extend(torch.argmax(model(data['image'].cuda())[0],dim = 1).cpu().detach().numpy())\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/98 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|| 98/98 [00:10<00:00,  9.71it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ8hrdagKMuK",
        "outputId": "64b4dd8c-53c0-4212-b1b1-f6f590601fe9"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "\n",
        "df = pd.DataFrame(data_file)\n",
        "\n",
        "\n",
        "gp = df.groupby('gt')\n",
        "\n",
        "\n",
        "vals = gp.aggregate(statistics.mode).iloc[:,0:-1]\n",
        "\n",
        "\n",
        "mapping = { j[0]:i  for i,j in zip(list(vals.index),vals.values)}\n",
        "\n",
        "# for i,j in zip(list(vals.index),vals.values):\n",
        "\n",
        "#   print(i,j)\n",
        "mapping\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "keys are the  preds and values are the gt. \n",
        "\n",
        "we will be mapping the preds to gt targets.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df['mapped_preds'] = df['pred'].map(lambda x : mapping[x])\n",
        "\n",
        "# df[['gt','mapped_preds']]    \n",
        "\n",
        "accuracy_score(df['gt'].values,df['mapped_preds'].values)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88684"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "fLxQWI3_KQCZ",
        "outputId": "7bea6ae7-609c-4a7f-932d-88532b09bc5b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix \n",
        "import seaborn as sns \n",
        "\n",
        "sns.heatmap(confusion_matrix(df['gt'].values,df['mapped_preds'].values))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdbad347550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5CH66ilKSMS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}